import os
import glob
import math
import numpy as np
import rasterio
from rasterio.merge import merge as rio_merge
from rasterio.vrt import WarpedVRT
from rasterio.enums import Resampling
from rasterio.transform import from_bounds
from rasterio.warp import transform_bounds
from collections import Counter
import gc


def list_tifs(input_dir, recursive=True):
    pattern = "**/*.tif" if recursive else "*.tif"
    files = glob.glob(os.path.join(input_dir, pattern), recursive=recursive)
    files = [f for f in files if os.path.isfile(f)]
    files.sort()
    return files


def analyze_file_data_coverage(file_path, sample_count=5):
    """
    PhÃ¢n tÃ­ch coverage chi tiáº¿t cá»§a file báº±ng cÃ¡ch láº¥y nhiá»u sample
    """
    try:
        with rasterio.open(file_path) as src:
            width, height = src.width, src.height
            
            # Láº¥y multiple samples tá»« cÃ¡c vá»‹ trÃ­ khÃ¡c nhau
            sample_positions = [
                (0, 0),  # Top-left
                (width//2, height//2),  # Center
                (width-100, height-100),  # Bottom-right
                (width//4, height//4),  # Quarter
                (3*width//4, 3*height//4),  # Three-quarter
            ]
            
            total_valid = 0
            total_sampled = 0
            
            for i, (x_start, y_start) in enumerate(sample_positions):
                if x_start >= width or y_start >= height:
                    continue
                    
                sample_size = min(100, width - x_start, height - y_start)
                if sample_size <= 0:
                    continue
                
                try:
                    window = rasterio.windows.Window(x_start, y_start, sample_size, sample_size)
                    sample = src.read(1, window=window)
                    
                    # Äáº¿m valid pixels theo nhiá»u tiÃªu chÃ­
                    if np.issubdtype(sample.dtype, np.floating):
                        # Float: check NaN vÃ  finite
                        valid_mask = np.isfinite(sample) & ~np.isnan(sample)
                        if src.nodata is not None:
                            valid_mask = valid_mask & (sample != src.nodata)
                    else:
                        # Integer: check nodata value
                        if src.nodata is not None:
                            valid_mask = sample != src.nodata
                        else:
                            valid_mask = np.ones_like(sample, dtype=bool)
                    
                    valid_count = np.sum(valid_mask)
                    total_valid += valid_count
                    total_sampled += sample.size
                    
                    print(f"     Sample {i+1} [{x_start}:{x_start+sample_size}, {y_start}:{y_start+sample_size}]: "
                          f"{valid_count}/{sample.size} valid ({100*valid_count/sample.size:.1f}%)")
                    
                    # Show actual values
                    if valid_count > 0:
                        valid_values = sample[valid_mask]
                        print(f"       Data range: {valid_values.min():.4f} to {valid_values.max():.4f}")
                    else:
                        unique_vals = np.unique(sample.flatten())[:5]  # First 5 unique values
                        print(f"       Unique values: {unique_vals}")
                        
                except Exception as e:
                    print(f"     Sample {i+1} error: {e}")
                    continue
            
            overall_coverage = (total_valid / total_sampled * 100) if total_sampled > 0 else 0
            return overall_coverage
            
    except Exception as e:
        print(f"   âŒ Cannot analyze coverage: {e}")
        return None


def print_file_info(file_path):
    try:
        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        with rasterio.open(file_path) as src:
            print(f"ğŸ“„ {os.path.basename(file_path)} | {src.width}x{src.height} | bands={src.count} | "
                  f"crs={src.crs} | res={src.res} | dtype={src.dtypes[0]} | nodata={src.nodata} | {file_size_mb:.1f}MB")
            print(f"   bounds: {src.bounds}")
            
            # **THÃŠM: PhÃ¢n tÃ­ch coverage chi tiáº¿t**
            if file_size_mb > 1000:  # File > 1GB
                print(f"   âš ï¸ LARGE FILE: {file_size_mb:.1f}MB - Analyzing data coverage...")
                coverage = analyze_file_data_coverage(file_path)
                if coverage is not None:
                    print(f"   ğŸ“Š Overall coverage: {coverage:.1f}%")
                    if coverage > 0:
                        print(f"   âœ… File contains valid data!")
                    else:
                        print(f"   âš ï¸ File appears to be empty or all NoData")
            else:
                # Quick check for smaller files
                sample_size = min(100, src.width, src.height)
                sample = src.read(1, window=((0, sample_size), (0, sample_size)))
                
                if np.issubdtype(sample.dtype, np.floating):
                    valid_pixels = np.sum(np.isfinite(sample) & ~np.isnan(sample))
                    if src.nodata is not None:
                        valid_pixels = np.sum((sample != src.nodata) & np.isfinite(sample))
                else:
                    valid_pixels = np.sum(sample != src.nodata) if src.nodata is not None else sample.size
                
                coverage = (valid_pixels / sample.size) * 100
                print(f"   ğŸ“Š Sample coverage: {coverage:.1f}% (quick check)")
                    
    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c file {file_path}: {e}")


def safe_merge_with_memory_management(srcs, method='first', nodata=None):
    """
    Merge files vá»›i memory management cho file lá»›n
    """
    print(f"ğŸ”„ Safe merge with memory management...")
    
    # PhÃ¢n loáº¡i files theo kÃ­ch thÆ°á»›c
    large_files = []
    normal_files = []
    
    for i, src in enumerate(srcs):
        file_size_mb = os.path.getsize(src.name) / (1024 * 1024)
        if file_size_mb > 1000:  # > 1GB
            large_files.append((i, src, file_size_mb))
            print(f"  ğŸ“¦ Large file {i}: {os.path.basename(src.name)} ({file_size_mb:.1f}MB)")
        else:
            normal_files.append((i, src, file_size_mb))
    
    print(f"  ğŸ“Š Normal files: {len(normal_files)}, Large files: {len(large_files)}")
    
    if len(large_files) == 0:
        # KhÃ´ng cÃ³ file lá»›n â†’ dÃ¹ng merge bÃ¬nh thÆ°á»ng
        print("  âœ… No large files, using standard merge...")
        return rio_merge(srcs, method=method.lower(), nodata=nodata)
    
    else:
        # CÃ³ file lá»›n â†’ dÃ¹ng VRT approach
        print("  ğŸ”„ Large files detected, using VRT approach...")
        
        try:
            # **KIá»‚M TRA**: Äáº£m báº£o nodata Ä‘Æ°á»£c set Ä‘Ãºng
            if nodata is None:
                # Tá»± Ä‘á»™ng detect nodata tá»« sources
                nodata_candidates = [src.nodata for src in srcs if src.nodata is not None]
                if nodata_candidates:
                    nodata = nodata_candidates[0]
                    print(f"  ğŸ”§ Auto-detected nodata value: {nodata}")
                else:
                    # Set default nodata cho float
                    if srcs[0].dtypes[0] == 'float32':
                        nodata = -9999.0
                    else:
                        nodata = -9999
                    print(f"  ğŸ”§ Using default nodata value: {nodata}")
            
            # Táº¡o VRT cho tá»«ng file Ä‘á»ƒ tiáº¿t kiá»‡m memory
            vrt_srcs = []
            for src in srcs:
                vrt = WarpedVRT(src, 
                               crs=srcs[0].crs,
                               nodata=nodata,  # Äáº£m báº£o nodata Ä‘Æ°á»£c set
                               resampling=Resampling.nearest)
                vrt_srcs.append(vrt)
            
            # Merge VRTs thay vÃ¬ files gá»‘c
            mosaic, transform = rio_merge(vrt_srcs, method=method.lower(), nodata=nodata)
            
            # Cleanup VRTs
            for vrt in vrt_srcs:
                vrt.close()
            
            return mosaic, transform
            
        except Exception as e:
            print(f"  âŒ VRT approach failed: {e}")
            # Fallback: Thá»­ merge tá»«ng file má»™t cÃ¡ch tuáº§n tá»±
            return sequential_merge(srcs, method, nodata)


def sequential_merge(srcs, method='first', nodata=None):
    """
    Merge files tuáº§n tá»± Ä‘á»ƒ trÃ¡nh memory overflow
    """
    print("  ğŸ”„ Sequential merge fallback...")
    
    if len(srcs) == 1:
        data = srcs[0].read()
        return data, srcs[0].transform
    
    # Báº¯t Ä‘áº§u vá»›i 2 files Ä‘áº§u tiÃªn
    print(f"    Merging files 1-2...")
    mosaic, transform = rio_merge(srcs[:2], method=method.lower(), nodata=nodata)
    gc.collect()  # Free memory
    
    # Merge tá»«ng file tiáº¿p theo
    for i in range(2, len(srcs)):
        print(f"    Adding file {i+1}...")
        
        # Táº¡o temporary raster tá»« mosaic hiá»‡n táº¡i
        temp_profile = srcs[0].profile.copy()
        temp_profile.update({
            'height': mosaic.shape[1],
            'width': mosaic.shape[2],
            'transform': transform,
            'dtype': mosaic.dtype,
            'nodata': nodata
        })
        
        # Ghi temporary file
        temp_path = f"/tmp/temp_mosaic_{i}.tif"
        with rasterio.open(temp_path, 'w', **temp_profile) as temp_dst:
            temp_dst.write(mosaic)
        
        # Merge temp file vá»›i file tiáº¿p theo
        with rasterio.open(temp_path) as temp_src:
            mosaic, transform = rio_merge([temp_src, srcs[i]], method=method.lower(), nodata=nodata)
        
        # Cleanup
        os.remove(temp_path)
        gc.collect()
    
    return mosaic, transform


def analyze_output_data(output_path):
    """
    PhÃ¢n tÃ­ch dá»¯ liá»‡u trong file output
    """
    try:
        print(f"\nğŸ” ANALYZING OUTPUT DATA:")
        with rasterio.open(output_path) as src:
            # Äá»c toÃ n bá»™ band Ä‘áº§u tiÃªn (hoáº·c sample lá»›n náº¿u file quÃ¡ lá»›n)
            if src.width * src.height > 100_000_000:  # > 100M pixels
                # File ráº¥t lá»›n, chá»‰ sample
                sample_data = src.read(1, window=rasterio.windows.Window(0, 0, 
                                                                       min(1000, src.width), 
                                                                       min(1000, src.height)))
                print(f"  ğŸ“Š Analyzing sample: {sample_data.shape}")
            else:
                sample_data = src.read(1)
                print(f"  ğŸ“Š Analyzing full data: {sample_data.shape}")
            
            # PhÃ¢n tÃ­ch data
            total_pixels = sample_data.size
            
            if np.issubdtype(sample_data.dtype, np.floating):
                finite_mask = np.isfinite(sample_data)
                nan_count = np.sum(np.isnan(sample_data))
                inf_count = np.sum(np.isinf(sample_data))
                
                if src.nodata is not None:
                    nodata_count = np.sum(sample_data == src.nodata)
                    valid_mask = finite_mask & (sample_data != src.nodata)
                else:
                    nodata_count = 0
                    valid_mask = finite_mask
                
                valid_count = np.sum(valid_mask)
                
                print(f"  ğŸ“ˆ Total pixels: {total_pixels:,}")
                print(f"  âœ… Valid pixels: {valid_count:,} ({100*valid_count/total_pixels:.2f}%)")
                print(f"  ğŸš« NoData pixels: {nodata_count:,}")
                print(f"  âš ï¸ NaN pixels: {nan_count:,}")
                print(f"  âš ï¸ Inf pixels: {inf_count:,}")
                
                if valid_count > 0:
                    valid_data = sample_data[valid_mask]
                    print(f"  ğŸ“Š Data range: {valid_data.min():.6f} to {valid_data.max():.6f}")
                    print(f"  ğŸ“Š Data mean: {valid_data.mean():.6f}")
                    print(f"  ğŸ“Š Data std: {valid_data.std():.6f}")
                
            else:
                if src.nodata is not None:
                    valid_count = np.sum(sample_data != src.nodata)
                    nodata_count = np.sum(sample_data == src.nodata)
                else:
                    valid_count = total_pixels
                    nodata_count = 0
                
                print(f"  ğŸ“ˆ Total pixels: {total_pixels:,}")
                print(f"  âœ… Valid pixels: {valid_count:,} ({100*valid_count/total_pixels:.2f}%)")
                print(f"  ğŸš« NoData pixels: {nodata_count:,}")
                
                if valid_count > 0:
                    valid_data = sample_data[sample_data != src.nodata] if src.nodata is not None else sample_data
                    print(f"  ğŸ“Š Data range: {valid_data.min()} to {valid_data.max()}")
            
    except Exception as e:
        print(f"  âŒ Error analyzing output: {e}")


def merge_directory(input_dir, output_path, method='first', nodata=None, recursive=True, use_safe_merge=True):
    """
    Merge Táº¤T Cáº¢ .tif trong thÆ° má»¥c thÃ nh 1 áº£nh - ENHANCED VERSION cho file lá»›n
    method: 'first'|'last'|'min'|'max'|'sum'|'count'|'mean'
    nodata: giÃ¡ trá»‹ NoData
    use_safe_merge: Sá»­ dá»¥ng safe merge cho file lá»›n
    """
    tif_paths = list_tifs(input_dir, recursive=recursive)
    if not tif_paths:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file .tif nÃ o trong thÆ° má»¥c.")
        return False

    print(f"ğŸ“‚ TÃ¬m tháº¥y {len(tif_paths)} file .tif - MERGE Táº¤T Cáº¢:")
    for i, p in enumerate(tif_paths, 1):
        print(f"  {i}. {os.path.basename(p)}")
    print("-" * 80)

    # Print detailed info
    total_size_mb = 0
    for p in tif_paths:
        print_file_info(p)
        total_size_mb += os.path.getsize(p) / (1024 * 1024)
    
    print(f"ğŸ“Š Tá»•ng dung lÆ°á»£ng input: {total_size_mb:.1f} MB")
    print("-" * 80)

    # Má»Ÿ táº¥t cáº£ files
    srcs = []
    failed_files = []
    for path in tif_paths:
        try:
            src = rasterio.open(path)
            srcs.append(src)
        except Exception as e:
            print(f"âŒ Cannot open {os.path.basename(path)}: {e}")
            failed_files.append(path)
    
    if not srcs:
        print("âŒ KhÃ´ng thá»ƒ má»Ÿ file nÃ o!")
        return False
    
    if failed_files:
        print(f"âš ï¸ {len(failed_files)} file khÃ´ng thá»ƒ má»Ÿ, tiáº¿p tá»¥c vá»›i {len(srcs)} files")
    
    try:        
        print(f"ğŸ¯ Target CRS: {srcs[0].crs}")
        print(f"ğŸ“Š Merge {len(srcs)} áº£nh thÃ nh 1 áº£nh duy nháº¥t báº±ng method '{method}'")
        
        if use_safe_merge and total_size_mb > 2000:  # > 2GB
            print(f"ğŸ”€ Using SAFE MERGE (total size: {total_size_mb:.1f}MB > 2GB)...")
            mosaic, transform = safe_merge_with_memory_management(srcs, method, nodata)
        else:
            print(f"ğŸ”€ Using STANDARD MERGE (total size: {total_size_mb:.1f}MB)...")
            mosaic, transform = rio_merge(srcs, method=method.lower(), nodata=nodata)
        
        print(f"âœ… Merge completed! Mosaic shape: {mosaic.shape}")
        
        # Chuáº©n bá»‹ metadata tá»« file Ä‘áº§u tiÃªn
        out_meta = srcs[0].meta.copy()
        out_meta.update({
            "driver": "GTiff",
            "height": mosaic.shape[1],
            "width": mosaic.shape[2],
            "transform": transform,
            "dtype": mosaic.dtype,
            "compress": "LZW",
            "tiled": True,
            "BIGTIFF": "YES" if total_size_mb > 1000 else "NO",
            "blockxsize": 512,
            "blockysize": 512,
        })
        
        # Set nodata náº¿u Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
        if nodata is not None:
            out_meta.update({"nodata": nodata})

        # Äáº£m báº£o thÆ° má»¥c output tá»“n táº¡i
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        # Ghi file
        print(f"ğŸ’¾ Writing to: {output_path}")
        with rasterio.open(output_path, "w", **out_meta) as dest:
            dest.write(mosaic)

        # **THÃŠM: PhÃ¢n tÃ­ch output data**
        analyze_output_data(output_path)

        # Clear memory
        del mosaic
        gc.collect()

        # Final report
        if os.path.exists(output_path):
            actual_size_mb = os.path.getsize(output_path) / (1024 * 1024)
            print("=" * 80)
            print("âœ… MERGE HOÃ€N THÃ€NH!")
            print(f"ğŸ“ Output: {output_path}")
            print(f"ğŸ“Š ÄÃ£ merge: {len(srcs)} áº£nh â†’ 1 áº£nh")
            print(f"ğŸ“ KÃ­ch thÆ°á»›c: {out_meta['width']:,} x {out_meta['height']:,} x {out_meta['count']} bands")
            print(f"ğŸ’¾ Dung lÆ°á»£ng file: {actual_size_mb:.1f} MB")
            print(f"ğŸ§­ CRS: {srcs[0].crs}")
            print(f"ğŸš« NoData: {out_meta.get('nodata', 'None')}")
            print("=" * 80)
            return True
        else:
            print("âŒ Output file was not created!")
            return False

    except Exception as e:
        print(f"âŒ Lá»—i khi merge: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        for s in srcs:
            try: 
                s.close()
            except: 
                pass


if __name__ == "__main__":
    # Import config for flexible path resolution  
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent))
    from config import get_data_root, get_project_root, ensure_dirs
    
    # ====== CONFIGURATION ======
    DATA_ROOT = get_data_root()
    
    # Use environment variables for configuration
    REGION_NAME = os.getenv("REGION_NAME", "VietNamFlood_20221015")
    INPUT_DIR = str(DATA_ROOT / "GEE_EXPORTS/DEM/tiles")
    OUTPUT_FILE = str(DATA_ROOT / f"GEE_EXPORTS/DEM/{REGION_NAME}_DEM.tif")
    MERGE_METHOD = "first"   # 'first'|'last'|'min'|'max'|'sum'|'count'|'mean'
    NODATA_VALUE = None      # None for auto-detect, or set -9999
    
    # Ensure output directory exists
    ensure_dirs([Path(OUTPUT_FILE).parent])
    
    print(f"ğŸ“ Merge Configuration:")
    print(f"   Input dir: {INPUT_DIR}")
    print(f"   Output file: {OUTPUT_FILE}")

    print("ğŸš€ ENHANCED MERGE - PHÃ‚N TÃCH CHI TIáº¾T DATA")
    print("=" * 80)
    ok = merge_directory(INPUT_DIR, OUTPUT_FILE, method=MERGE_METHOD, nodata=NODATA_VALUE, 
                        recursive=True, use_safe_merge=True)
    print("ğŸ‰ THÃ€NH CÃ”NG!" if ok else "âŒ THáº¤T Báº I!")